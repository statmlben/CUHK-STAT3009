\frametitle{Holdout Cross-validation: Ridge regression}
^^I\begin{equation*}
^^I^^I\widehat{\mb{\theta}} = \argmin_{\mb{\theta}} \ \frac{1}{n} \sum_{i=1}^n \big( \text{out}_i - \mb{\theta}^\intercal(\text{feat}_i) \big)^2 + \lambda \| \mb{\theta} \|^2_2.
^^I\end{equation*}
^^I\begin{itemize}
^^I\item $\lambda \nearrow \implies$ \blue{less weight} in fitting or \blue{reduce} the model complexity
^^I\item[Results] Cross-validation \red{ridge regression}:
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize]
alpha: 0.5; train_mse: 0.519; valid_mse: 0.5231
alpha: 1.0; train_mse: 0.519; valid_mse: 0.5231
alpha: 10.0; train_mse: 0.519; valid_mse: 0.5230 (best)
alpha: 50.0; train_mse: 0.520; valid_mse: 0.5233
alpha: 100.0; train_mse: 0.522; valid_mse: 0.5246
alpha: 1000.0; train_mse: 0.575; valid_mse: 0.5784
\end{lstlisting}
^^I\item \red{optimal} {penalty} weight = 10
\end{itemize}
